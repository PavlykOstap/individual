{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'path_to_new_image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FUJITSU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FUJITSU\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функція для зміни розміру зображення\n",
    "def resize_image(img, size=(400, 400)):\n",
    "    return cv2.resize(img, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Не вдалося завантажити зображення за шляхом: {img_path}\")\n",
    "    img = resize_image(img)\n",
    "    img = img.astype('float32') / 255.0  # нормалізація\n",
    "    img = np.transpose(img, (2, 0, 1))  # переміщення каналів\n",
    "    img = torch.tensor(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path):\n",
    "    image = process_image(image_path).unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted_class_idx = torch.max(output, 1)\n",
    "    return predicted_class_idx.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функція для обробки анотації\n",
    "def process_annotation(annot_path, class_to_idx):\n",
    "    with open(annot_path) as f:\n",
    "        annotation = xmltodict.parse(f.read())\n",
    "    # Витягування мітки класу з анотації\n",
    "    objects = annotation['annotation']['object']\n",
    "    if isinstance(objects, list):\n",
    "        label = class_to_idx[objects[0]['name']]\n",
    "    else:\n",
    "        label = class_to_idx[objects['name']]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, annotations, class_to_idx):\n",
    "        self.images = images\n",
    "        self.annotations = annotations\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        annot_path = self.annotations[idx]\n",
    "        image = process_image(img_path)\n",
    "        label = process_annotation(annot_path, self.class_to_idx)\n",
    "        return image, label\n",
    "\n",
    "images_folder = 'images'  # Назва папки з зображеннями\n",
    "annotations_folder = 'annotations'  # Назва папки з анотаціями\n",
    "\n",
    "images = []\n",
    "annotations = []\n",
    "\n",
    "for filename in os.listdir(images_folder):\n",
    "    if filename.endswith('.png'):\n",
    "        image_path = os.path.join(images_folder, filename)\n",
    "        annotation_path = os.path.join(annotations_folder, filename[:-4] + '.xml')\n",
    "        if os.path.exists(annotation_path):\n",
    "            images.append(image_path)\n",
    "            annotations.append(annotation_path)\n",
    "\n",
    "if len(images) != len(annotations):\n",
    "    raise ValueError(\"Кількість зображень та анотацій не співпадає\")\n",
    "\n",
    "# Створення списку всіх унікальних класів\n",
    "unique_classes = set()\n",
    "\n",
    "for annot_path in annotations:\n",
    "    with open(annot_path) as f:\n",
    "        annotation = xmltodict.parse(f.read())\n",
    "        objects = annotation['annotation']['object']\n",
    "        if isinstance(objects, list):\n",
    "            for obj in objects:\n",
    "                unique_classes.add(obj['name'])\n",
    "        else:\n",
    "            unique_classes.add(objects['name'])\n",
    "\n",
    "class_names = list(unique_classes)\n",
    "class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "train_images, test_images, train_annotations, test_annotations = train_test_split(images, annotations, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = ImageDataset(train_images, train_annotations, class_to_idx)\n",
    "test_dataset = ImageDataset(test_images, test_annotations, class_to_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визначення моделі\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 100 * 100, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 100 * 100)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "num_classes = len(class_to_idx)  # Залежить від кількості класів дорожніх знаків\n",
    "model = SimpleCNN(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.452285102822564\n",
      "Epoch 2, Loss: 0.6654881225390867\n",
      "Epoch 3, Loss: 0.5139357515356757\n",
      "Epoch 4, Loss: 0.3748157146302136\n",
      "Epoch 5, Loss: 0.21805250204422258\n"
     ]
    }
   ],
   "source": [
    "# Навчання моделі\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.13636363636364%\n"
     ]
    }
   ],
   "source": [
    "# Оцінка моделі\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зображення успішно завантажено з розмірами: (179, 281, 3)\n"
     ]
    }
   ],
   "source": [
    "test_image_path = 'path_to_new_image/path_to_new_image.png'\n",
    "img = cv2.imread(test_image_path)\n",
    "if img is None:\n",
    "    raise FileNotFoundError(f\"Не вдалося завантажити зображення за шляхом: {test_image_path}\")\n",
    "print(\"Зображення успішно завантажено з розмірами:\", img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зображення змінено за розміром до: (400, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "def resize_image(img, size=(400, 400)):\n",
    "    return cv2.resize(img, size)\n",
    "\n",
    "resized_img = resize_image(img)\n",
    "print(\"Зображення змінено за розміром до:\", resized_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зображення перетворено на тензор з формою: torch.Size([3, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = resized_img.astype('float32') / 255.0  # нормалізація\n",
    "img = np.transpose(img, (2, 0, 1))  # переміщення каналів\n",
    "img_tensor = torch.tensor(img)\n",
    "print(\"Зображення перетворено на тензор з формою:\", img_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Передбачений клас: 0\n"
     ]
    }
   ],
   "source": [
    "# Використання моделі для передбачення\n",
    "img_tensor = img_tensor.unsqueeze(0)  # додати розмір для batch\n",
    "with torch.no_grad():\n",
    "    outputs = model(img_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "print(f'Передбачений клас: {predicted.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точність моделі Random Forest: 0.7102\n",
      "Точність моделі Gradient Boosting: 0.6989\n"
     ]
    }
   ],
   "source": [
    "def load_data(images_path, annotations_path, image_size=(64, 64)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for annotation_file in os.listdir(annotations_path):\n",
    "        if annotation_file.endswith('.xml'):\n",
    "            annotation_path = os.path.join(annotations_path, annotation_file)\n",
    "            image_file = annotation_file.replace('.xml', '.png')  # Змінено розширення на .png\n",
    "            image_path = os.path.join(images_path, image_file)\n",
    "            \n",
    "            if os.path.exists(image_path):\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                image = image.resize(image_size)\n",
    "                image = np.array(image)\n",
    "                images.append(image)\n",
    "                \n",
    "                tree = ET.parse(annotation_path)\n",
    "                root = tree.getroot()\n",
    "                \n",
    "                label = root.find('object').find('name').text  # Отримуємо мітку з імені об'єкта\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                print(f\"Зображення не знайдено: {image_path}\")\n",
    "        else:\n",
    "            print(f\"Анотація не є .xml файлом: {annotation_file}\")\n",
    "                    \n",
    "    if not images:\n",
    "        print(\"Не завантажено жодного зображення.\")\n",
    "    if not labels:\n",
    "        print(\"Не завантажено жодної анотації.\")\n",
    "    \n",
    "    X = np.array(images)\n",
    "    y = np.array(labels)\n",
    "    return X, y\n",
    "\n",
    "# Вказівка шляхів до папок\n",
    "images_path = 'images'\n",
    "annotations_path = 'annotations'\n",
    "\n",
    "# Завантаження даних\n",
    "X, y = load_data(images_path, annotations_path)\n",
    "\n",
    "# Розділення даних на тренувальну та тестову вибірки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Перетворення зображень на одномірні вектори\n",
    "X_train_flattened = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "# Модель Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_flattened, y_train)\n",
    "rf_predictions = rf_model.predict(X_test_flattened)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Точність моделі Random Forest: {rf_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Перетворення зображень на одномірні вектори\n",
    "X_train_flattened = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "# Модель Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train_flattened, y_train)\n",
    "gb_predictions = gb_model.predict(X_test_flattened)\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
    "print(f\"Точність моделі Gradient Boosting: {gb_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
